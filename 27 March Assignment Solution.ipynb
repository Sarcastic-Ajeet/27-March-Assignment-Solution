{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it represent?\n",
    "### Ans.\n",
    "R-square is known as the ratio of sum of squared error with the sum fo square of the total. It determine how a best fit line is fitting to the predicted point.It's value lie between 0 to 1 mainly,In case best fit line is more far then the pridicted point than it can go beyond the 1.<br>\n",
    "r-square=1-sse/sst <br>\n",
    "r-square=1−∑(yi−^yi)2/∑(yi−¯y)2 <br>\n",
    "sse=(yi-^yi) <br>\n",
    "sst=∑(yi−¯y)2 <br>\n",
    "The sum squared error is the sum of the residuals squared, and the total sum of squares is the sum of the distance the data is away from the mean all squared.\n",
    "[For example visit]( https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/coefficient-of-determination-r-squared.html#:~:text=Solution,into%20the%20regression%20line%20equation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Define adjusted R-squared and explain how it differs from the regular R-squared. \n",
    "### Ans.\n",
    "It the modified form of the r-square.In adjusted r-square we added the no of indepemdent variable term, so when the no of indepemdent variable increase, adjusted r-square increases.It is always a positive number and greater then r-square.<br>\n",
    "The most obvious difference between adjusted R-squared and R-squared is simply that adjusted R-squared considers and tests different independent variables against the stock index and R-squared does not.<br>\n",
    "Adjusted r-square=(1-r^2)(n-1)/(n-p-1)<br>\n",
    "r^2=r-squre<br>\n",
    "n=size of the data<br>\n",
    "p=total no  of independent variable<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. When is it more appropriate to use adjusted R-squared?\n",
    "### Ans.\n",
    "It is preferred to use when there are many independent variable.we ican chechk how they are affecting by changing the no of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4,Q5. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics calculated, and what do they represent?\n",
    "### Ans.\n",
    "#### Mean Square Error(MSE):\n",
    "Mean square error calculate the error between the best fit line point and the original line point.It is the sum of squared error.<br>\n",
    "mse=∑(yi-yi^)^2/n<br>\n",
    "It is diffentiable and have a local minima.<br>\n",
    "It is not robust to outlier.<br>\n",
    "It is not in the same unit.\n",
    "#### Mean Absolute Error(MAE):\n",
    "The Mean absolute error represents the average of the absolute difference between the actual and predicted values in the dataset.<br>\n",
    "mae=∑|yi-yi^|/n<br>\n",
    "It is in the same unit  and robust to outlier<br>\n",
    "but it is's optimization is complex and convergence usually takes time.\n",
    "#### Root Mean Square Error(MSE):\n",
    "Root Mean Squared Error is the square root of Mean Squared error. It measures the standard deviation of residuals.<br>\n",
    "rmse=$\\sqrt{mse}$ <br>\n",
    "It is in same unit and differentiable.<br>\n",
    "It is not robust to outliers.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is it more appropriate to use?\n",
    "### Ans.\n",
    "#### Lasso Regression (L1 Regularization):\n",
    "Lasso regression is used to overcome the overfitting problems.Sometimes the our training dataset is low but high variance.then weneed to perform lasso It added a anotherterm in the mean square error that is absolute cofficient or slope.<br>\n",
    "lasso regression = mse+$\\lambda$ ∑|slope|<br>\n",
    "It is used for feature selection. it drops less correlated independent variables.<br>\n",
    "#### Ridge Regression (l2 Regularization):\n",
    "It is also used for overcome the overfitting problem.<br>\n",
    "Ridge regression = mse+$\\lambda$ ∑(slope)^2<br>\n",
    "l2 regularization reduces the overfiting.It is used when every feature has some impect and we don't want to eliminate them.<br>\n",
    "Both are approprite according to need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an example to illustrate.\n",
    "### Ans.\n",
    "by adding a penality term ($\\lambda$ ∑(slope)^2), $\\lambda$ ∑|slope|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best choice for regression analysis.\n",
    "### Ans.\n",
    "............................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9. You are comparing the performance of two regression models using different evaluation metrics. Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better performer, and why? Are there any limitations to your choice of metric?\n",
    "### Ans.\n",
    "I will chose the Model b with mae of 8. It will give absolute value without affecting by the outliers.\n",
    "if i choose model a it will increse my sqaure error and will giove them as doubled error. And rmse is not robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10. You are comparing the performance of two regularized linear models using different types of regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the better performer, and why? Are there any trade-offs or limitations to your choice of regularization method?\n",
    "### Ans.\n",
    "I will chose model B,beacause 0.5 lambda error is less then then squared error. Yeah i Will lose some feature when i apply lasso but it wiil be more accurate. But in Ridge regression threre error will take the fprm of its square and it will comsider all the feature either they correlated or not.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
